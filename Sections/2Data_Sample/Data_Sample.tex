The data used for the analyses were the AOD samples of the following four datasets:  	LHC17p$\_$pass1$\_$FAST, LHC17p$\_$pass1$\_$CENT$\_$woSDD, LHC17q$\_$pass1$\_$FAST and LHC17q$\_$pass1$\_$CENT$\_$woSDD . The reason for choosing these data samples (in particular, those without the drifts for the CENT cluster) is explained later on, in this section. It was verified, by looking at D-meson and associated charged track $\eta$ and $\varphi$ distributions, and at the mixed-event correlation distributions for each sub-samples, that no visible differences is present for the four periods, hence it was possible to perform the analysis directly on the merged samples without any bias.

The Monte Carlo productions adopted for this study were:
 \begin{enumerate}
 \item LHC18a4a2$\_$fast, a HF production (HIJING with GEANT3) anchored to LHC17p/q is with enrichment of heavy quarks (charm and beauty) and their decay products in each of the event, performed by PYTHIA6 with Perugia2011 tune, and with forced hadronic decays of the charmed hadrons. This production was used for D-meson efficiency evaluation, purity estimation and Monte Carlo closure test.
 \item LHC17l3b$\_$fast, minimum-bias samples produced with DPMJET generator, are used for the evaluation of the tracking efficiencies.
\end{enumerate}

Table 1 shows the list of runs used for the analysis, for each of the data taking periods, and of the Monte Carlo productions used to evaluate the corrections:
\newpage
% Systematic table
\begin{table}[h]
\begin{tabular}{ p{1.0cm} | p{4.9cm} |  p{6.6cm} |  p{1.2cm}}
{\normalsize \textbf {Type}} &       {\normalsize \textbf {Production}} &       {\normalsize \textbf {Run list}} & {\normalsize \textbf {nEvents}} \\
\\ \hline
Monte-Carlo & LHC18a4a2$\_$fast (c/b enriched) [GEANT3] &282343, 282342, 282341, 282340, 282314, 282313, 282312, 282309, 282307, 282306, 282305, 282304, 282303, 282302, 282247, 282230, 282229, 282227, 282224, 282206, 282189, 282147, 282146, 282127, 282126, 282125, 282123, 282122, 282120, 282119, 282118, 282099, 282098, 282078, 282051, 282050, 282031, 282025, 282021, 282016, 282008,282367, 282366, 282365 $~~~~~~~~~~~~~~~~$ = \textbf{[44 runs]} & 23M\\

& LHC17l3b$\_$fast (Minimum Bias sample) [GEANT3] &282008, 282016, 282021, 282025, 282031, 282050, 282051, 282078, 282098, 282099, 282118, 282119, 282120, 282122, 282123, 282125, 282126, 282127, 282146, 282147, 282189, 282206, 282224, 282227, 282229, 282230, 282247, 282302, 282303, 282304, 282305, 282306, 282307, 282309, 282312, 282313, 282314, 282340, 282341, 282342, 282343, 282365, 282366, 282367 $~~~~~~~~~~~~~~~~$ = \textbf{[44 runs]} & 23M\\
\\ \hline

\multirow{7}{*}{} Data& LHC17p$\_$pass1$\_$FAST & 282343, 282342, 282341, 282340, 282314, 282313, 282312, 282309, 282307, 282306, 282305, 282304, 282303, 282302, 282247, 282230, 282229, 282227, 282224, 282206, 282189, 282147, 282146, 282127, 282126, 282125, 282123, 282122, 282120, 282119, 282118, 282099, 282098, 282078, 282051, 282050, 282031, 282025, 282021, 282016, 282008  = \textbf{[41 runs]}& 985M total\\
                  & LHC17p$\_$pass1$\_$CENT$\_$woSDD &282343, 282342, 282341, 282340, 282314, 282313, 282312, 282309, 282307, 282306, 282305, 282304, 282303, 282302, 282247, 282230, 282229, 282227, 282224, 282206, 282189, 282147, 282146, 282127, 282126, 282125, 282123, 282122, 282120, 282119, 282118, 282099, 282098, 282078, 282051, 282050, 282031, 282030, 282025, 282021, 282016, 282008  = \textbf{[42 runs]} &  \\
% \\ \hline
 & LHC17q$\_$pass1$\_$FAST & 282367, 282366, 282365  = \textbf{[3 runs]} &  \\
% \\ \hline
  & LHC17q$\_$pass1$\_$CENT$\_$woSDD& 282367, 282366, 282365  = \textbf{[3 runs]} & \\
 \hline \hline
\label{tab:Sample}
\end{tabular}
\\
\caption {Data Set and Run list}
\end{table}

The trigger mask request for the event selection is kINT7. Only events with a reconstructed primary vertex within 10 cm from the centre of the detector along the beam line are considered. This choice maximises the detector coverage of the selected events, considering the longitudinal size of the interaction region, and
the detector pseudorapidity acceptances. 
Beam-gas events are removed by offline selections based on the timing information provided by the V0 and the Zero Degree Calorimeters, and the correlation between the number of hits and track segments in the SPD detector. This is automatically performed in the Physic Selection, a positive outcome of which is required during our event selection. The pile-up cuts for out-of-bunch pile-up protection are also invoked when calling the Physics Selection task.
The minimum-bias trigger efficiency is 100\% for events with D mesons with $\pt > 1$ $\gev/c$. For the analyzed data samples, the probability of pile-up from collisions in the same bunch crossing is below 2\% per triggered event (in most of the runs, well below 1\%). Events in which more than one primary interaction vertex is reconstructed with the SPD detector (with minimum of 5 contributors, and a $z$ distance greater than 0.8 cm) are rejected, which effectively removes the impact of in-bunch pile-up events on the analysis. Out-of-bunch tracks are effectively rejected by the Physics Selection pile-up cuts, and also by the request of at least one point in the SPD, which has a very limited time acquisition window (300 ns). Indeed, though the default associated track selection requires a minimum of 2 points in the ITS, as it will be shown later on full compatibility of the corrected results with 2 and 3 minimum ITS clusters are obtained. For FAST and CENT$\_$woSDD samples, the latter case indirectly forces the presence of a point in the SPD.

Since data collected during pp 2017 data taking are distinguished into two categories - one including SDD detector (CENT$\_$wSDD sample) and the second one without the SDD in the reconstruction, or in the acquisition (CENT$\_$woSDD and FAST samples, respectively), a study of performance of the D-hadron correlation analysis with respect to the data samples employed has been carried out on p-Pb 2016 data for $\Dstar$ and $\Dplus$ mesons (more sensitive to the presence of the SDD w.r.t. the $\Dzero$, due to their reconstruction from three decay tracks) refer to p-Pb 2016 analysis note. By using the same analogy, the pp data analysis also done on the similar data samples.


