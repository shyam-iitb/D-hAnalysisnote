The data used for the analyses were the AOD samples of the following four datasets: LHC17p$\_$FAST, LHC17p$\_$CENT$\_$woSDD, LHC17q$\_$FAST and LHC17q$\_$CENT$\_$woSDD (in all the cases, exploiting the pass1 reconstruction). The reason for choosing these data samples (in particular, those without the drifts for the CENT cluster) is explained later on, in this section. Exactly as done in the p--Pb 2016 data sample, also split in a similar fashion, it was verified, by looking at D-meson and associated charged track $\eta$ and $\varphi$ distributions, and at the mixed-event correlation distributions for each sub-samples, that no visible differences is present for the four periods (though the 17q samples taken alone suffer from very large statistical uncertainties), hence it was possible to perform the analysis directly on the merged samples without any bias.

The Monte Carlo productions adopted for this study were:
 \begin{enumerate}
 \item LHC18a4a2$\_$fast, a HF production (HIJING with GEANT3) anchored to LHC17p,q with enrichment of heavy quarks (charm and beauty) in each of the event, produced by PYTHIA6 with Perugia2011 tune, and with forced hadronic decays of the charmed hadrons. This production was used for D-meson efficiency evaluation, purity estimation and Monte Carlo closure test.
 \item LHC17l3b$\_$fast, minimum-bias sample produced with DPMJET generator, used for the evaluation of the tracking efficiencies.
\end{enumerate}

Table 1 shows the list of runs used for the analysis, for each of the data taking periods, and of the Monte Carlo productions used to evaluate the corrections:
\newpage
% Systematic table
\begin{table}[h]
\begin{tabular}{ p{1.0cm} | p{4.9cm} |  p{6.6cm} |  p{1.2cm}}
\small
{\textbf {Type}} &       {\textbf {Production}} &       {\textbf {Run list}} & {\textbf {nEvents}} \\
\\ \hline
Monte-Carlo & LHC18a4a2$\_$fast (c/b enriched) [GEANT3] &282343, 282342, 282341, 282340, 282314, 282313, 282312, 282309, 282307, 282306, 282305, 282304, 282303, 282302, 282247, 282230, 282229, 282227, 282224, 282206, 282189, 282147, 282146, 282127, 282126, 282125, 282123, 282122, 282120, 282119, 282118, 282099, 282098, 282078, 282051, 282050, 282031, 282025, 282021, 282016, 282008,282367, 282366, 282365 $~~~~~~~~~~~~~~~~$ = \textbf{[44 runs]} & 23M\\

& LHC17l3b$\_$fast (Minimum Bias sample) [GEANT3] &282008, 282016, 282021, 282025, 282031, 282050, 282051, 282078, 282098, 282099, 282118, 282119, 282120, 282122, 282123, 282125, 282126, 282127, 282146, 282147, 282189, 282206, 282224, 282227, 282229, 282230, 282247, 282302, 282303, 282304, 282305, 282306, 282307, 282309, 282312, 282313, 282314, 282340, 282341, 282342, 282343, 282365, 282366, 282367 $~~~~~~~~~~~~~~~~$ = \textbf{[44 runs]} & 23M\\
\\ \hline

\multirow{7}{*}{} Data& LHC17p$\_$pass1$\_$FAST & 282343, 282342, 282341, 282340, 282314, 282313, 282312, 282309, 282307, 282306, 282305, 282304, 282303, 282302, 282247, 282230, 282229, 282227, 282224, 282206, 282189, 282147, 282146, 282127, 282126, 282125, 282123, 282122, 282120, 282119, 282118, 282099, 282098, 282078, 282051, 282050, 282031, 282025, 282021, 282016, 282008  = \textbf{[41 runs]}& 985M total\\
                  & LHC17p$\_$pass1$\_$CENT$\_$woSDD &282343, 282342, 282341, 282340, 282314, 282313, 282312, 282309, 282307, 282306, 282305, 282304, 282303, 282302, 282247, 282230, 282229, 282227, 282224, 282206, 282189, 282147, 282146, 282127, 282126, 282125, 282123, 282122, 282120, 282119, 282118, 282099, 282098, 282078, 282051, 282050, 282031, 282030, 282025, 282021, 282016, 282008  = \textbf{[42 runs]} &  \\
% \\ \hline
 & LHC17q$\_$pass1$\_$FAST & 282367, 282366, 282365  = \textbf{[3 runs]} &  \\
% \\ \hline
  & LHC17q$\_$pass1$\_$CENT$\_$woSDD& 282367, 282366, 282365  = \textbf{[3 runs]} & \\
 \hline \hline
\label{tab:Sample}
\end{tabular}
\\
\caption {Data Set and Run list}
\end{table}

The trigger mask request for the event selection is kINT7. Only events with a reconstructed primary vertex within 10 cm from the centre of the detector along the beam line are considered. This choice maximises the detector coverage of the selected events, considering the longitudinal size of the interaction region, and the detector acceptances, without introducing sizeable $\eta$ dependencies for the reconstruction efficiencies in the considered pseudorapidity ranges.
Beam-gas events are removed by offline selections based on the timing information provided by the V0 and the Zero Degree Calorimeters, and the correlation between the number of hits and track segments in the SPD detector. This is automatically performed in the Physic Selection, a positive outcome of which is required during our event selection. The pile-up cuts for out-of-bunch pile-up protection are also invoked when calling the Physics Selection task.
The minimum-bias trigger efficiency is 100\% for events with D mesons with $\pt > 1$ $\gev/c$. For the analyzed data samples, the probability of pile-up from collisions in the same bunch crossing is below 2\% per triggered event (in most of the runs, well below 1\%). Events in which more than one primary interaction vertex is reconstructed with the SPD detector are rejected (via a call to AliRDHFCuts::kRejectMVPileupEvent method with default parameters), which effectively removes the impact of pile-up events on the analysis. Out-of-bunch tracks are also effectively rejected by the Physics Selection pile-up cuts, and also by the request of at least one point in the SPD, which has a very limited time acquisition window (300 ns).

Since data collected during pp 2017 data taking are distinguished into two categories - one including SDD detector (CENT$\_$wSDD sample) and the second one without the SDD in the reconstruction, or in the acquisition (CENT$\_$woSDD and FAST samples, respectively), a study of performance of the D-hadron correlation analysis with respect to the data samples employed has been carried out for $\Dstar$ and $\Dplus$ mesons (more sensitive to the presence of the SDD w.r.t. the $\Dzero$, due to their reconstruction from three decay tracks), very similar of what was done for the p-Pb 2016 data sample (refer to p-Pb 2016 analysis note at \cite{NotepPb}), reaching exactly the same conclusion, of a more solid analysis being obtained using more uniform samples (FAST and CENT$\_$woSDD), at the price of a slight reduction of the statistical precision.


